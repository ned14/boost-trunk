\documentclass{kapproc}
%\usepackage{semantic}
%\usepackage{math}

%% uncomment to make footnote appear at bottom of page:
\let\footnote\savefootnote
%% uncomment if you want footnotetext to appear at the bottom of the page:
\let\footnotetext\savefootnotetext 

%% uncomment if you want a ruled line above the footnote:
\let\footnoterule\savefootnoterule 
%% How many levels of section head would you like numbered?
%% 0= no section numbers, 1= section, 2= subsection, 3= subsubsection
%%==>>
\setcounter{secnumdepth}{4}

%% How many levels of section head would you like to appear in the
%% Table of Contents?
%% 0= chapter titles, 1= section titles, 2= subsection titles, 
%% 3= subsubsection titles.
%%==>>
\setcounter{tocdepth}{4}
\kluwerbib

\newcommand{\Cpp}{C\kern-0.05em\texttt{+\kern-0.03em+}%
}
\newcommand{\Mpl}{Boost Meta\-pro\-gram\-ming Library}
\newcommand{\mping}{meta\-pro\-gram\-ming}
\newcommand{\mpgm}{meta\-pro\-gram}
\newcommand{\mpgms}{meta\-pro\-grams}
\newcommand{\mpgmer}{meta\-pro\-gram\-mer}
\newcommand{\mpgmers}{meta\-pro\-gram\-mer}
\newcommand{\mfn}{meta\-func\-tion}
\newcommand{\mfns}{meta\-func\-tions}
\newcommand{\mdat}{meta\-data}

\input{defs}

\begin{document}

\articletitle{The Boost \Cpp\ Metaprogramming Library}

\author{Aleksey Gurtovoy} 
 \affil{MetaCommunications, Inc.}
\email{agurtovoy@meta-comm.com}
\author{David Abrahams}
 \affil{Boost Consulting}
\email{david.abrahams@rcn.com}


\begin{abstract} $\!$This paper describes the Boost \Cpp Template
Meta\-program\-ming Library (MPL), an extensible compile-time
framework of algorithms, sequences and function classes. The library
brings together important abstractions from the generic and functional
programming worlds to build a powerful and easy-to-use toolset which
makes template \mping{} practical enough for the real-world
environments. The MPL is heavily influenced by its run-time equivalent
- the Standard Template Library (STL), a part of the C++ standard
library. Like the STL, it defines an open conceptual and
implementation framework which can serve as a foundation for future
contributions in the domain. The library's fundamental concepts and
idioms enable the user to focus on solutions without navigating the
universe of possible ad-hoc approaches to a given \mping{} problem,
even if no actual MPL code is used.  The \Mpl also provides a
compile-time lambda expression facility enabling arbitrary currying
and composition of class templates, a feature whose runtime
counterpart is often cited as missing from the STL. This paper
explains the motivation, usage, design, and implementation of the MPL
with examples of its real-life applications, and offers some lessons
learned about C++ template \mping{}.
\end{abstract}

\begin{keywords}
programming languages, type systems, generic programming,
polymorphism, metaprogramming, compile-time
\end{keywords}

%==============================================================================
\section{Introduction}

Metaprogramming is usually defined as the creation of programs which
generate other programs. Parser generators such as YACC are examples
of one kind of program-generating program. The input language to YACC
is a context-free grammar in EBNF, and its output is a program which
parses that grammar. Note that in this case the \mpgm{} (YACC) is
written in a language (`C') which does not directly support the
description of generated programs. These specifications, which we'll
call \emph{\mdat}, are not written in `C', but in a
\emph{meta-language}. Because the the rest of the user's program
typically requires a general-purpose programming system and must
interact with the generated parser, the \mdat\ is translated into
`C', which is then compiled and linked together with the rest of the
system. The \mdat\ thus undergoes two translation steps, and the
user is always very conscious of the boundary between his \mdat\
and the rest of his program.
% need bibliography reference for YACC

\subsection{Native Language Metaprogramming}

A more interesting form of \mping{} is available in languages
such as Scheme, where the generated program specification is given in
the same language as the \mpgm{} itself. The metaprogrammer
defines his meta-language as a subset of the expressible forms of the
underlying language, and program generation can take place in the same
translation step used to process the rest of the user's program. This
allows users to switch transparently between ordinary programming,
generated program specification, and \mping{}, often without
being aware of the transition.
% bib reference for Scheme metaprogramming

\subsection{Metaprogramming in \Cpp{}}

In \Cpp, it was discovered almost by accident \cite{Unr, Vel95} that 
the template mechanism provides a rich facility for computation at 
compile-time. In this section, we'll explore the basic mechanisms and 
some common idioms used for metaprogramming in C++.

\subsubsection{Numeric Computations}

The availability of \emph{non-type template parameters} makes it
possible to perform integer computations at compile-time. For example,
the following template computes the factorial of its
argument:

{\small
\begin{codesamp}\begin{verbatim}
template <unsigned n>
struct factorial
{
   static const unsigned value = n * factorial<n-1>::value;
};

template <>
struct factorial<0>
{
   static const unsigned value = 1;
};
\end{verbatim}
\end{codesamp}
}

The program fragment above is called a \emph{\mfn}, and it is easy to
see its relationship to a function designed to be evaluated at
runtime: the ``\mfn\ argument'' is passed as a template parameter, and
its ``return value'' is defined as a nested static constant.  Because
of the hard line between the expression of compile-time and runtime
computation in \Cpp, metaprograms look different from their runtime
counterparts. Thus, although as in Scheme the \Cpp\ \mpgmer\ writes
her code in the same language as the ordinary program, only a subset
of the full \Cpp\ language is available to her: those expressions
which can be evaluated at compile-time. Compare the above with a
straightforward runtime definition of the factorial function:

{\small
\begin{codesamp}\begin{verbatim}
unsigned factorial(unsigned N)
{
   return N == 0 ? 1 : N * factorial(N - 1);
}
\end{verbatim}
\end{codesamp}
}

While it is easy to see the analogy between the two recursive
definitions, recursion is in general more important to \Cpp{}
metaprograms than it is to runtime \Cpp. In contrast to languages such
as Lisp where recursion is idiomatic, \Cpp\ programmers will typically
avoid recursion when possible. This is done not only for efficiency
reasons, but also because of ``cultural momentum'': recursive programs
are simply harder (for \Cpp\ programmers) to think about. Like pure
Lisp, though, the \Cpp\ template mechanism is a \emph{functional}
programming language: as such it rules out the use of data mutation
required to maintain loop variables.

A key difference between the runtime and compile-time factorial
functions is the expression of the termination condition: our
meta-factorial uses template specialization as a kind of
\emph{pattern-matching} mechanism to describe the behavior when
\code{N} is zero. The syntactic analogue in the runtime world would
require two separate definitions of the same function. In this case
the impact of the second definition is minimal, but in large
metaprograms the cost of maintaining and understanding the terminating
definitions can become significant.

Note also that a \Cpp\ \mfn's return value must be \emph{named}. The
name chosen here, \code{value}, is the same one used for all numeric
returns in the \Mpl. As we'll see, establishing a consistent naming
convention for \mfn\ returns is crucial to the power of the library.

\subsubsection{Type Computations}

How could we apply our \code{factorial<>} \mfn{}? We might, for example,
produce an array type of an appropriate size to hold all permutations
of instances of another type:

{\small
\begin{codesamp}\begin{verbatim}
// permutation_holder<T>::type is an array type which can contain 
// all permutations of a given T.

// unspecialized template for scalars
template <class T> struct permutation_holder
{
   typedef T type[1][1];
};

// specialization for array types
template <class T, unsigned N> struct permutation_holder<T[N]>
{
   typedef T type[factorial<N>::value][N];
};
\end{verbatim}
\end{codesamp}
}

Here we have introduced the notion of a \emph{type computation}.  Like
\code{factorial<>} above, \code{permutation\_\-holder<>} is a
\mfn{}. However, where \code{{factorial<>}} manipulates unsigned integer
values, \code{permutation\_\-holder<>} accepts and ``returns'' a
type (as the nested typedef ``\code{type}''). Because the \Cpp\ type
system provides a much richer set of expressions than anything we can
use as a nontype template argument (e.g. the integers), \Cpp\ \mpgms\
tend to be composed mostly of type computations.

\subsubsection{Type Sequences}

The ability to programmatically manipulate collections of types is a
central tool of most interesting \Cpp\ metaprograms. Because this
capability is so well-supported by the MPL, we'll provide just a brief
introduction to the basics here.

First, we'd need a way to represent the collection. One
idea might be to store the types in a structure:

{\small
\begin{codesamp}\begin{verbatim}
struct types {
  int t1;
  long t2;
  std::vector<double> t3;
};
\end{verbatim}
\end{codesamp}
}

Unfortunately, this arrangement is not susceptible to the compile-time
type introspection power that \Cpp\ gives us: there's no way to find
out what the names of the members are, and even if we assume that
they're named according to some convention as above, there's no way to
now how many members there are. The key to solving this problem is to
increase the uniformity of the representation. If we have a consistent
way to get the first type of any sequence and the rest of the
sequence, we can easily access all members:

{\small
\begin{codesamp}\begin{verbatim}
template <class First, class Rest>
struct cons
{
  typedef First first;
  typedef Rest rest;
};

struct nil {};

typedef
  cons<int, cons<long, cons<std::vector<double>, nil> > >
my_types;
\end{verbatim}
\end{codesamp}
}

The structure described by \code{types} above is the compile-time
analogue of a singly-linked list. Now that we've adjusted the
structure so that the \Cpp\ template machinery can ``peel it apart'',
let's examine a simple function which does so. Suppose a user wished
to find the largest of an arbitrary collection of types. We can apply
the recursive \mfn\ formula which should by now be familiar:

{\small
\begin{codesamp}\begin{verbatim}
// Choose the larger of two types
template <class T1, class T2
        , bool choose1 = (sizeof(T1) > sizeof(T2)) // hands off!
        >
struct choose_larger
{
   typedef T1 type;
};

// specialization for the case where sizeof(T2) >= sizeof(T1)
template <class T1, class T2>
struct choose_larger<T1,T2,false>
{
   typedef T2 type;
};

// Get the largest of a cons-list
template <class T> struct largest;

// Specialization to peel apart the cons list
template <class First, class Rest>
struct largest<cons<First,Rest> >
   : choose_larger<First, typename largest<Rest>::type>
{
   // type inherited from base
};

// specialization for loop termination
template <class First>
struct largest<cons<First,nil> >
{
   typedef First type;
};

int main()
{
   // print the name of the largest of my_types
   std::cout << typeid(largest<my_types>::type).name()
             << std::endl;
}

\end{verbatim}
\end{codesamp}
}

There are several things worth noticing about this code:

\begin{itemize}
\item It uses a few ad-hoc, esoteric techniques, or ``hacks''. The
  default template argument \code{choose1} (labelled ``hands off!'')
  is one example. Without it, we would have needed yet another
  template to provide the implementation of \code{choose\_\-larger},
  or we would have had to provide the computation explicitly as a
  parameter to the template - perhaps not bad for this example, but it
  would make choose\_\-larger much less useful and more
  error-prone. The other hack is the derivation of a specialization of
  \code{largest} from \code{choose\_\-larger}. This is a code-saving
  device which allows the programmer to avoid writing \code{typedef
  typename}...\code{::type type} in the template body.

\item Even this simple \mpgm\ uses three separate partial
  specializations. The \code{largest} \mfn\ uses \emph{two}
  specializations. One might expect that this indicates there are two
  termination conditions, but there are not: one specialization is
  needed simply to deal with access to the sequence elements. These
  specializations make the code difficult to read by spreading the
  definition of a single \mfn\ over several \Cpp\ template
  definitions. Also, because they are \emph{partial} specializations,
  they make the code unusable for a large community of \Cpp\
  programmers whose compilers don't support that feature.
\end{itemize}

While these techniques are of course a valuable part of the arsenal of
any good \Cpp\ \mpgmer, their use tends to make programs written in
what is already an unusual style harder-to-read and
harder-to-write. By encapsulating commonly-used structures and dealing
with loop terminations internally, the \Mpl\ reduces the need for both
tricky hacks and for template specializations.

\subsection{Why Metaprogramming?}

%%% maybe we don't need another example of a metaprogram given what
%%% we've done above? We could rewrite and cut most of this section...

It's worth asking why anyone would want to do this. After all, even a
simple toy example like the factorial \mfn\ is somewhat
esoteric. To show how the type computation can be put to work, let's
examine a simple example. The following code produces an array
containing all possible permutations of another array:

{\small
\begin{codesamp}\begin{verbatim}
// Can't return an array in C++, so we need this wrapper
template <class T>
struct wrapper
{
   T x;
};

// Return an array of the N! permutations of x
template <class T>
wrapper<typename permutation_holder<T>::type>
all_permutations(T const& in)
{
   wrapper<typename permutation_holder<T>::type> result;

   // Copy the unpermuted array to the first result element
   unsigned const N = sizeof(T)/sizeof(**result.x);
   std::copy(&*in, &*in + N, result.x[0]);

   // Enumerate the permutations
   unsigned const result_size = sizeof(result.x)/sizeof(T);
   for (T* dst = result.x + 1; dst != result.x + result_size; ++dst)
   {
       T* src = dst - 1;
       std::copy(*src, *src + N, *dst);
       std::next_permutation(*dst, *dst + N);
   }
   return result;
}
\end{verbatim}
\end{codesamp}
}


%%% ...up to this point

The runtime definition of \code{factorial} would be useless in
\code{all\_\-permutations} above, since in \Cpp\ the sizes of array
members must be computed at compile-time. However, there are
alternative approaches; how could we avoid \mping, and what would the
consequences be?

\begin{enumerate}

\item We could write programs to interpret the \mdat\ directly. In
  our factorial example, the array size could have been a runtime
  quantity; then we'd have been able to use the straightforward
  factorial function. However, that would imply the use of dynamic
  allocation, which is often expensive.

  To carry this further, YACC might be rewritten to accept a
  pointer-to-function returning tokens from the stream to be parsed,
  and a string containing the grammar description. This approach,
  however, would impose unacceptable runtime costs for most
  applications: either the parser would have to treat the grammar
  nondeterministically, exploring the grammar for each parse, or it
  would have to begin by replicating at runtime the substantial
  table-generation and optimization work of the existing YACC for each
  input grammar.

\item We could replace the compile-time computation with our own
  analysis. After all, the size of arrays passed to
  \code{all\_\-permutations} are always known at compile-time, and
  thus can be known to its user. We could ask the user to supply the
  result type explicitly:
{\small
\begin{codesamp}\begin{verbatim}
template <typename Result, typename T>
Result
all_permutations(T const& input);
\end{verbatim}
\end{codesamp}
}
  The costs to this approach are obvious: we give up expressivity (by
  requiring the user to explicitly specify implementation details),
  and correctness (by allowing the user to specify them
  incorrectly). Anyone who has had to write parser tables by hand will
  tell you that the impracticality of this approach is the very reason
  YACC's existence.

  In a language such as \Cpp, where the \mdat\ can be expressed in
  the same language as the rest of the user's program, expressivity is
  further enhanced: the user can invoke \mpgms\ directly, without
  learning a foreign syntax or interrupting the flow of his code.
\end{enumerate}

So, the motivation for \mping{} comes down to the combination of three
factors: efficiency, expressivity, and correctness. While in classical
programming there is always a tension between expressivity and
correctness on one hand and efficiency on the other, in the \mping\
world we wield new power: can move the computation required for
expressivity from runtime to compile-time.

\subsection{Why a Metaprogramming \emph{Library}?}

One might just as well ask why we need any generic library: 
 
\begin{itemize}

\item Quality. Code that is appropriate for a general-purpose library
  is usually incidental to the purpose of its users. To a library
  developer, it is the central mission. On average, the containers and
  algorithms provided by any given \Cpp\ standard library
  implementation are more-flexible and better-implemented than the
  project-specific implementations which abound, because library
  development was treated as an end in itself rather than a task
  incidental to the development of some other application. With a
  centralized implementation for any given function, optimizations and
  improvements are more likely to have been applied.

\item Re-use. More important even than the re-use of code which all
  libraries provide, a well-designed generic library establishes a
  \emph{framework of concepts and idioms} which establish a reusable
  mental model for approaching problems. Just as the \Cpp\ Standard
  Template Library gave us iterator concepts and a function object
  protocol, the \Mpl\ provides type-iterators and meta-function class
  protocol. A well-considered framework of idioms saves the \mpgmer{}
  from considering irrelevant implementation details and allows her to
  concentrate on the problem at hand.

\item Portability. A good library can smooth over the ugly realities
  of platform differences. While in theory a \mping\ library is fully
  generic and shouldn't be concerned with these issues, in practice,
  support for templates remains inconsistent even four years after
  standardization. This should perhaps not be surprising: \Cpp\
  templates are the language's furthest-reaching and most complicated
  feature, which largely accounts for the power of \mping\ in \Cpp.

\item Fun. Repeating the same idioms over and over is
  \emph{tedious}. It makes programmers tired and reduces
  productivity. Furthermore, when programmers get bored they get
  sloppy, and buggy code is even more costly than slowly-written
  code. Often the most useful libraries are simply patterns that have
  been ``plucked'' by an astute programmer from a sea of
  repetition. The MPL helps to reduce boredom by eliminating the need
  for the most commonly-repeated boilerplate coding patterns.

\end{itemize}

As you can see, the \Mpl's development is motivated primarily by the
same practical, real-world considerations that justify the development
of any other library. Perhaps this is an indication that template
\mping\ is finally ready to leave the realm of the esoteric and enter
the lingua franca of every day programmers.
%probably this paragraph would be better in the conclusions

\subsection{What about portability? }

Although the MPL aims to reduce the user's need to be concerned with
issues of nonstandard \Cpp\ implementations, some concessions are
inevitable. For example, the current implementation of the
\code{lambda} facility does not work on compilers which lack either
support for template partial specialization or for template template
parameters.\footnote{We believe that a workaround is possible, but
that it would impose some additional restrictions on the way users
must represent \mfn{}s. The fact remains that without both
features, \mping\ expressivity is somewhat reduced.} Another
concession which may not be apparent at first is the need for the
\code{apply1}...\code{applyN} templates. On most compilers,
\code{applyN<F,T1,T2...TN>} (for example) is derived from
\code{F::template apply<T1,T2...TN>}: it is nearly a synonym, and one
might well wonder whether it is even worth providing \code{apply} as a
library facility since the language construct only costs one
additional keyword. On one compiler, however, this construct causes an
internal compiler error and must be replaced with a workaround so
odious that it would be unreasonable to expect even an expert to find
it.\footnote{In fact, the workaround isn't even legal \Cpp\, but it is
accepted by the compiler in question.} The library hides all this
nastiness within its implementation of \code{applyN}, but anyone
writing portable \mpgms\ is required to use the library instead of
taking what might be considered the more obvious approach.

\section{Basic usage (What can I do with mpl?)}

\subsection{Conditional type selection}

Conditional type selection is the simplest basic construct of \Cpp\
template \mping{}. Veldhuizen \cite{Vel95a} was the first to show 
how to implement it, and Czarnecki and Eisenecker \cite{CE00} first 
presented it as a standalone library primitive. The \Mpl\ defines the 
corresponding facility as follows:

%%% It would be a good idea to introduce/motivate the use of true_c/false_c
%%% types in place of bool parameters. 

{\small
\begin{codesamp}\begin{verbatim}
// definition
template<
      typename Condition
    , typename T1
    , typename T2
    >
struct select_if
{
    typedef implementation-defined type;
};

// usage/semantics
typedef mpl::select_if<mpl::true_c,char,long>::type t1;
typedef mpl::select_if<mpl::false_c,char,long>::type t2;

BOOST_MPL_ASSERT_IS_SAME(t1, char);
BOOST_MPL_ASSERT_IS_SAME(t2, long);
\end{verbatim}
\end{codesamp}
}

The construct is important because template \mpgms{} often 
contain a lot of decision-making code, and, as we will show, 
spelling it manually every time via (partial) class template 
specialization quickly becomes impractical. The template also 
important from the point of encapsulating the compiler 
workarounds (for example, not all \Cpp\ compilers support 
partial template specialization). 

\subsubsection{Delayed Evaluation}

The way \Cpp\ template instantiation mechanism works imposes some
subtle limitations on applicability of the type selection primitive,
compared to a manually implemented equivalent of the selection code.

%%% This section digresses into dealing with what I would title
%%% "Delayed Evaluation". While a /very/ important topic, I would
%%% cover it elsewhere, enabling you to avoid using Partial Spec. as
%%% an excuse for dealing with it. Delayed evaluation for correctness
%%% deserves a mention but I think you might have one too many
%%% examples of unsuccessful attempts to deal with it ;-) 

For example, suppose we are implementing a \code{pointed\_\-type}
traits template such as \code{pointed\_\-type<T>::type} instantiated
for a \code{T} that is either a plain pointer
(\code{U*}), \code{std::auto\_\-ptr<U>}, or any of the \code{boost}
smart pointers, e.g. \code{boost::\-scoped\_\-ptr<U>}, will give you 
the pointed type (\code{U}):

{\small
\begin{codesamp}\begin{verbatim}
BOOST_MPL_ASSERT_IS_SAME(pointed_type<my*>::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< std::auto_ptr<my> >::type, my);
BOOST_MPL_ASSERT_IS_SAME(pointed_type< boost::scoped_ptr<my> >::type, my);
\end{verbatim}
\end{codesamp}
}


Unfortunately, the straightforward application of \code{select\_\-if}
to this problem does not work:\footnote{Although it would be easy to
implement \code{pointed\_\-type} using partial specialization to
distinguish the case where \code{T} is a pointer, \code{select\_\-if}
is likely to be the right tool for dealing with more--complex
conditionals. For the purposes of exposition, please suspend
disbelief!}

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
    : mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename T::element_type // #1
        >
{
};

// the following code causes compilation error in line #1:
// name followed by "::" must be a class or namespace name
typedef pointed_type<char*>::type result;
\end{verbatim}
\end{codesamp}
}

Clearly, the expression \code{typename T::element\_\-type} is not
valid in case of \code{T == char*}, and that's what the compiler is
complaining about. Implementing the selection code manually solves the
problem:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
// general case
template<typename T, bool is_pointer = false>
struct select_pointed_type
{
  typedef typename T::element_type type;
};

// specialization for plain pointers
template<typename  T>
struct select_pointed_type<T,true>
{
  typedef typename boost::remove_pointer<T>::type type;
};
}

template< typename T >
struct pointed_type
   : aux::select_pointed_type<
          T, boost::is_pointer<T>::value
        >
{
};
\end{verbatim}
\end{codesamp}
}

But this quickly becomes awkward if needs to be done repeatedly, and
this awkwardness is compounded when partial specialization is not
available. We can try to work around the problem as follows:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
template< typename T >
struct element_type
{
     typedef typename T::element_type type;
};
}

template< typename T >
struct pointed_type
{
    typedef typename mpl::select_if<
          boost::is_pointer<T>
        , typename boost::remove_pointer<T>::type
        , typename aux::element_type<T>::type
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

but this doesn't work either - the access to the 
\code{element\_\-type<T>}'s nested \code{type} member still 
forces the compiler to instantiate \code{element\_\-type<T>}
with \code{T == char*}, and that instantiation is of course 
invalid. Also, although in our case this does not lead to a 
compile error, the \code{boost::remove\_\-pointer<T>} template 
gets always instantiated as well, and for the same reason 
(because we are accessing it's nested \code{type} member). 
Such unnecessary instantiation that is not fatal from 
compiler's point of view may or may be not a problem, 
depending on the ``weight'' of the template (how much the 
instantiation taxes the compiler), but a general rule of 
thumb would be to avoid such code.

Returning to our error, to make the above code compile, we 
need to factor the act of ``asking'' \code{aux::element\_\-type<T>}
of its nested \code{type} out of the \code{select\_\-if} 
invocation. The fact that both \code{boost::remove\_\-pointer<T>}
trait template and \code{aux::element\_\-type<T>} use the same 
naming convention for their result types makes the refactoring 
easier:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
{
 private:
    typedef typename mpl::select_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type func_;

 public:
    typedef typename func_::type type;
};
\end{verbatim}
\end{codesamp}
}

Now the compiler has no reasons instantiate both 
\code{boost::remove\_\-pointer<T>} and 
\code{aux::element\_\-type<T>} even although they are used as 
actual parameters to the \code{select\_\-if} template (and is 
guaranteed not to do so), so we are guaranteed to get away with 
\code{aux::element\_\-type<char*>} as far as it won't end up being 
selected as \code{func\_}.

The above technique is so common in template metaprograms, that it
even make sense to facilitate the selection of nested \code{type} member
by introducing a high level equivalent to \code{select\_\-if} - the one
that will do \code{func\_::type} operation (that is called [nullary]
function class application) as a part of its invocation.  The MPL
provides such template - it's called \code{apply\_if}. Using it, we
can re-write the above code as simple as:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T >
struct pointed_type
{
    typedef typename mpl::apply_if<
          boost::is_pointer<T>
        , boost::remove_pointer<T>
        , aux::element_type<T>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

To make our techniques review complete, let's consider a slightly 
different example - suppose we want to define a high-level wrapper 
around \code{boost::remove\_\-pointer} traits template, which will 
strip the pointer qualification conditionally. We will call it 
\code{remove\_\-pointer\_\-if}:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename mpl::select_if<
          Condition
        , typename boost::remove_pointer<T>::type
        , T
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

Now the above works the first time, but it suffers from the problem we
mentioned earlier - \code{boost::remove\_\-pointer<T>} gets
instantiated even if its result is never used. In the \mping\ world
compilation time is an important resource \cite{Abr01}, and it is
wasted by unnecessary template instantiations. We've just seen how to
deal with the problem in when both arguments to \code{select\_\-if}
are the results of nullary function class applications, but in this
example one of the arguments (\code{T}) is just a simple type,
so the refactoring just doesn't seem possible. An easiest way out of
this situation would be to pass to \code{select\_\-if} a real nullary
function instead of \code{T}, - the one that returns \code{T} on its
invocation. The \Mpl provides a simple way to do it - we just
substitute \code{mpl::identity<T>} and \code{mpl::apply\_\-if} for \code{T} and
\code{mpl::select\_\-if}:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Condition
    , typename T
    >
struct remove_pointer_if
{
    typedef typename mpl::apply_if<
          Condition
        , boost::remove_pointer<T>
        , mpl::identity<T>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

Which gives us exactly what we wanted.

%%% This intro material needs to come earlier, since you talk about
%%% nullary functions in the previous section.  

\subsection{The Form of Metafunctions}

In \Cpp\, the basic underlying language construct which allows
parameterized compile-time computation is the \emph{class template}. A
bare class template is the simplest possible model we could choose for
\mfns: it can take types and/or non-type arguments as actual template
parameters and instantiation ``returns'' a new type. For example, the
following produces a type derived from its arguments:

{\small
\begin{codesamp}\begin{verbatim}
template<class N1, class N2>
struct derive : N1, N2
{
};
\end{verbatim}
\end{codesamp}
}

However, this model is far too limiting: it restricts the \mfn\ result
not only to class types, but to instantiations of a given class
template, to say nothing of the fact that every \mfn\ invocation
introduces an additional level of template nesting. While that might
be acceptable for this particular \mfn\, any model which prevented us
from ``returning'', say, \code{int} is obviously not general
enough. To meet this basic requirement, we must rely on a nested type
to provide our return value:

{\small
\begin{codesamp}\begin{verbatim}
template<class N1, class N2>
struct derive
{
  struct type : N1, N2 {};
};
// silly specialization, but demonstrates ``returning'' int.
template<>
struct derive<void,void>
{
  typedef int type;
};
\end{verbatim}
\end{codesamp}
}

Veldhuizen \cite{Vel95a} was first to talk about class templates of this
form as ``compile-time functions'', and \cite{CE00} have introduced
``template \mfn'' as an equivalent term (they also use the simpler
term ``\mfn'' as do we). 

\subsubsection{Higher-Order Metafunctions}

While syntactically simple, the simple template \mfn\ form does not
always interact optimally with the rest of \Cpp. In particular, the
simple \mfn\ form makes it unneccesarily awkward and tedious to define
and work with higher-order \mfns\ (\mfns\ that operate on other
\mfns). In order to pass a simple \mfn\ to another template, we need
to use \emph{template template parameters}:

{\small
\begin{codesamp}\begin{verbatim}
// Returns F(T1,F(T2,T3))
template<template<typename>class F, class T1, class T2, class T3>
struct apply_twice
{
  typedef typename F<
        T1
        , typename F<T2,T3>::type
  >::type type;
};

// A new metafunction returning a type derived from T1, T2, and T3
template <class T1, class T2, class T3>
struct derive3
  : apply_twice<derive,T1,T2,T3>
{};
\end{verbatim}
\end{codesamp}
}

This looks different, but it seems to work.\footnote{In fact it's
  already broken: \code{apply\_\-twice} doesn't even fit the \mfn\
  concept since it requires a template (rather than a type) as its first
  parameter, which breaks the \mfn\ protocol!} However, things begin
  to break down noticeably when we want to ``return'' a \mfn\ from our
  \mfn:

{\small
\begin{codesamp}\begin{verbatim}
// Returns G s.t. G(T1,T2,T3) == F(T1,F(T2,T3))
template<template<typename>class F>
struct compose_self
{
  template <class T1, class T2, class T3> 
  struct type : apply_twice<F,T1,T2,T3> {};
};
\end{verbatim}
\end{codesamp}
}

The first and most obvious problem is that the result of applying
\code{compose\_\-self} is not itself a type, but a template, so it
can't be passed in the usual ways to other \mfns. A more subtle issue,
however, is that the \mfn\ ``returned'' is not exactly what we
intended. Although it acts just like \code{apply\_\-twice}, it differs
in one important respect: its identity. In the \Cpp\ type system,
\code{compose\_\-self<F>::template type<T,U,V>} is not a synonym for
\code{apply\_\-twice<F,T,U,V>}, and any \mpgm\ which compared \mfns\
would discover that fact.

Because \Cpp\ makes a strict distinction between type and class
template template parameters, reliance on simple \mfns\ creates a
``wall'' between \mfns\ and \mdat, relegating \mfns\ to the
status of second-class citizens. For example, recalling our
introduction to type sequences, there's no way to make a \code{cons}
list of \mfns:

{\small
\begin{codesamp}\begin{verbatim}
typedef cons<derive, cons<derive3, nil> > derive_functions; // error!
\end{verbatim}
\end{codesamp}
}

We might consider redefining our \code{cons} cell so we can pass
\code{derive} as the head element:

{\small
\begin{codesamp}\begin{verbatim}
template <
    template<template<class T,class U> class F
  , class Tail
> struct cons;
\end{verbatim}
\end{codesamp}
}

However, now we have another problem: \Cpp\ templates are polymorphic
with respect to their type arguments, but not with respect to template
template parameters. The arity (number of parameters) of any template
template parameter is strictly enforced, so we \emph{still} can't
embed \code{derive3} in a \code{cons} list. Moreover, polymorphism
\emph{between} types and \mfns\ is not supported (the compiler expects
one or the other), and as we've seen, the syntax and semantics of
``returned'' \mfns\ is different from that of returned types. Trying
to accomplish everything with the simple template \mfn\ form would
seriously limit the applicability of higher-order \mfns and would have
an overall negative effect on the both conceptual and implementation
clarity, simplicity and size of the library.

\subsubsection{Metafunction Classes}

Fortunately, the truism that ``there is no problem in software
which can't be solved by adding yet another level of
indirection''\footnote{Andrew Koening calls this ``The Fundamental
Theorem of Software Engineering''} applies here. To elevate \mfns\ to
the status of first-class objects, the MPL introduces the concept of a
``\mfn\ class'':

{\small
\begin{codesamp}\begin{verbatim}
// metafunction class form of derive
struct derive
{
  template<class N1, class N2>
  struct apply
  {
    struct type : N1, N2 {};
  };
};
\end{verbatim}
\end{codesamp}
}

This form should look familiar to anyone acquainted with function
objects in STL, with the nested \code{apply} template taking the same
role as the runtime function-call operator. In fact, compile-time
metafunction classes have the same relationship to metafunctions that
runtime function objects have to functions:

{\small
\begin{codesamp}\begin{verbatim}
// function form of add
template <class T> T add(T x, T y) { return x + y; }

// function object form of add
struct add
{
  template<class T>
  T operator()(T x, T y) { return x + y; }
};
\end{verbatim}
\end{codesamp}
}

%% Based on the above, I don't see how to justify the statement
%% below. For example, how would a template typedef help me to put a
%% metafunction into a cons list?
%%
%% two forms exist because of some idiosyncrasy in 
%% how templates are defined in C++, - in particular, because 
%% of the lack of so called template typedefs \cite{Sut01}. 

\subsubsection{One Size Fits All?}

The \mfn\ class form solves all the problems with ordinary template
\mfns\ mentioned earlier: since it is a regular class, it can be
placed in compile-time \mdat\ sequences, and manipulated by other
\mfns\ using the same protocols as for any other \mdat. We thereby
avoid the code-duplication needed to provide versions of each library
component to operate on ordinary \mdat\ and on \mfns\ with each
distinct supported arity.

On the other hand, it seems that accepting \mfn\ classes as \emph{the}
representation for compile-time function entities imposes code
duplication danger as well: if the library's own primitives,
algorithms, etc. are represented as class templates, that means that
you either cannot reuse these algorithms in the context of
higher-order functions, or you have to duplicate all algorithms in the
second form, so, for instance, there would be two versions of
\code{find}:

{\small
\begin{codesamp}\begin{verbatim}
// user-friendly form
template<
      typename Sequence
    , typename T
    >
struct find
{
    typedef /* ... */ type;
};

// "function class" form
struct find_func
{
    template< typename Sequence, typename T >
    struct apply
    {
        typedef /* ... */ type;
    };
};
\end{verbatim}
\end{codesamp}
}

Of course, the third option is to eliminate ``user-friendly form''
completely so one would always have to write:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find::apply<list,long>::type iter;
// or, if you prefer,
// typedef mpl::apply< mpl::find,list,long >::type iter;
\end{verbatim}
\end{codesamp}
}

instead of 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find<list,long>::type iter;
\end{verbatim}
\end{codesamp}
}

That too would hurt usability, considering that the direct 
invocations of library's algorithms are far more often-used than 
passing algorithms as arguments to another algorithms/functions. 

\subsubsection{From Metafunction to Metafunction Class}

The MPL's answer to this dilemma is lambda expressions.  Lambda is the
mechanism that enables the library to curry \mfns\ and convert them
into function classes, so when you want to pass the \code{find}
algorithm as an argument to a higher-order function, you just write:

{\small
\begin{codesamp}
typedef mpl::apply< my\_f, \underline{mpl::find<\_1,\_2>} >::type result;
\end{codesamp}
}

Where \code{\_1} and \code{\_2} are placeholders for the first and
second arguments to the resulting \mfn\ class. This preserves the
intuitive syntax below for when the user wants to use \code{find}
directly in her code:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find<list,long>::type iter;
\end{verbatim}
\end{codesamp}
}

%%% Should say ``metafunction classes'' below?

Metafunctions are important by encapsulating an operation into 
compile-time invocable entity, they give you a possibility to 
defer its execution. You can store the entity, pass it around, 
and invoke the operation at any time you need.

\subsection{Sequences, algorithms, and iterators}

Compile-time iteration over a sequence (of types) is one of 
the basic concept of template metaprogramming. Difference in 
types of objects being manipulated is the most common point 
of variability of similar but not identical code/design, and 
such designs are the direct target for some metaprogramming. 
Templates in their original usage were intended to be used to 
solve this exact problem, (std::vector), but without predefined 
abstractions/constructs for manipulating/iterating 
\emph{sequences} of types instead of standalone types, and 
without developed (known) techniques for emulating this 
constructs using the current language facilities, they effect 
on helping high-level metaprogramming happen has been limited. 

Czarnecki and Eisenecker \cite{CE00} were the first to introduce 
the compile-time sequences of types and some simple algorithms 
on them, although the idea of representation common data 
structures like trees, lists, etc. at compile time using class 
template composition has been around for a while (for example, 
most of the expression template libraries build such trees as 
a part of their expression ``parsing'' process \cite{Vel95b}). 
\cite{Ale01} used list of types and some algorithms on them to 
implement several design patterns; the accompanying code 
is known as the Loki library. 

%%%\emph{OLD introduction:}

%%%A possibility to represent and manipulate theoretically 
%%%unbound sequences of types and values at compile time opens an 
%%%exciting opportunities for creating highly reusable, 
%%%configurable, and amazingly easy-to-use generic components and 
%%%classes \cite{CE00, Ale01}. Compile-time-operable collections of 
%%%types (and, to a slightly less extent, values) are at least as 
%%%important in generic and template metaprogramming as their 
%%%run-time equivalents in traditional programming. 
%%%The \Mpl acknowledges this assertion by providing an 
%%%STL-like framework of sequence, algorithm and function classes 
%%%that can significantly simplify building of complex 
%%%generic/generative components/systems. 

\subsubsection{Algorithms Operate on Sequences}
  
Most of algorithms in \Mpl\ operates on sequences. For example, 
searching type in a list looks like this:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list< char,short,int,long,float,double > types;
typedef mpl::find< types,long >::type iter;
\end{verbatim}
\end{codesamp}
}

Here, \code{find} accepts two parameters - a sequence to search
(\code{types}), the type to search for (\code{long}), and returns an
iterator \code{iter} pointing to the first element of the sequence
such that \code{iter::type} is identical to \code{long}; if no such
element exists, \code{iter} is identical to
\code{end<types>::type}. Basically, this is how one would search for a
value in \code{std::list} or \code{std::vector}, except that
\code{mpl::find} accepts the sequence as a single parameter,
while \code{std::find} takes two iterators.  Everything else is pretty
much the same - the names are the same, the semantics is very close,
there are iterators, and you can search not only by type, but also
using a predicate:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::find_if< types,boost::is_float<_1> >::type iter;
\end{verbatim}
\end{codesamp}
}

This conceptual/syntactical similarity with the STL is not
coincidental. Reusing the conceptual framework of STL in compile-time
world allows us to apply familiar and sound approaches for dealing
with sequential data structures. The algorithms and idioms which
programmers already know from STL can be applied again at
compile-time. We consider this to be one of the greatest strengths
that distinguishes the library from earlier attempts to build a
template metaprogramming library.

\subsubsection{Sequence Concepts}

In the \code{find} example above we searched for a type in the
sequence built using the \code{mpl::list} template, but
\code{list} is not the only sequence that the library provides you
with. Neither is\code{mpl::find} or any other algorithm
hard-coded to work only with \code{list} sequences. \code{list} is
just one model of MPL's ForwardSequence concept, and \code{find} works
with anything that satisfies this concept's requirements. The
hierarchy of sequence concepts in MPL is quite simple - a Sequence is
any compile-time entity for which \code{begin<>} and \code{end<>}
produce iterators to the range of its elements; a ForwardSequence is a
sequence whose iterators satisfy ForwardIterator requirements, a
BidirectionalSequence is a ForwardSequence whose iterators satisfy
BidirectionalIterator requirements, and, finally, RandomAccessSequence
is a BidirectionalSequence whose iterators satisfy
RandomAccessIterator requirements.

Decoupling algorithms from particular sequence implementation s
(through iterators) allows a \mpgmer\ to create her own sequence types
and to retain the rest of the library at her disposal. For example,
you can define a \code{tiny\_\-list} for dealing with sequences of 3
types as follows:

{\small
\begin{codesamp}\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_item;

template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
};

template< typename T0, typename T1, typename T2 >
struct tiny_list
{
    typedef tiny_list_iterator<tiny_list, 0> begin;
    typedef tiny_list_iterator<tiny_list, 3> end;
    typedef T0 type0;
    typedef T1 type1;
    typedef T2 type2;
};

template< typename TinyList >
struct tiny_list_item<TinyList,0>
{ typedef typename TinyList::type0 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,1>
{ typedef typename TinyList::type1 type; };

template< typename TinyList >
struct tiny_list_item<TinyList,2>
{ typedef typename TinyList::type2 type; };
\end{verbatim}
\end{codesamp}
}

and then use it with any of the library algorithms as if it 
was \code{mpl::list}:

{\small
\begin{codesamp}\begin{verbatim}
typedef tiny_list< char,short,int > types;
typedef mpl::transform<
      types
    , boost::add_pointer
    >::type pointers;
\end{verbatim}
\end{codesamp}
}

Note that \code{tiny\_\-list} is a model of 
BidirectionalSequence (it would be RandomAccess if 
we added \code{advance} member to \code{tiny\_\-list\_\-iterator}:

{\small
\begin{codesamp}\begin{verbatim}
template< typename TinyList, long Pos >
struct tiny_list_iterator
{
    typedef typename tiny_list_item<TinyList,Pos>::type type;
    typedef tiny_list_iterator<TinyList, Pos-1> prior;
    typedef tiny_list_iterator<TinyList, Pos+1> next;
    template< typename N > struct advance
    {
        typedef tiny_list_iterator<
              TinyList
            , Pos + N::value
            > type;
    };
};
\end{verbatim}
\end{codesamp}
}

).

While the \code{tiny\_\-list} itself might be not that 
interesting - after all, it can hold only 3 elements, if 
the technique above can be automated so we would be able to 
define not so tiny sequence - with 5, 10, 20, etc. number 
of elements, when it would be very valuable (random access 
is almost as important at compile-time as it is at run-time 
- for example searching something in a sorted random-access 
sequence using \code{lower\_\-bound} can be much faster than 
doing the same operation 
on forward-access only \code{list}). External code generation 
is one option here, but there is also a solution within the 
language, although it's not a template metaprogramming, 
but preprocessor metaprogramming \cite{PRE}. In fact, 
\code{mpl::vector} - a fixed-size type sequence that 
provides random-access iterators - is implemented very like 
the above \code{tiny\_\-list}. 

\subsubsection{Why Library-Provided Iteration is Important}

So, the library provides you with almost complete compile-time 
equivalent of STL framework. Does it help you to solve you 
metaprogramming tasks? Let's return to our \code{largest} 
example to see if we can rewrite it in a better way with what 
\code{mpl} has to offer. Well, actually there is not 
much to look at, because implementation of it with MPL is a 
one-liner (we'll spread it out here for readability):

{\small
\begin{codesamp}\begin{verbatim}
template< typename Sequence >
struct largest
{
    typedef typename mpl::max_element<
          Sequence
        , mpl::less<
              mpl::size_of<_1>
            , mpl::size_of<_2>
            >
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

No more termination conditions with a tricky pattern matching, 
no more partial specializations, and even more importantly, 
it's \emph{obvious} what the above code does - even although 
it's all templates - something that you cannot say about the 
original version.

\subsubsection{iter\_fold as the main iteration 
algorithm}

For the purpose of examining a little bit more of the library's
internal structure, let's look at how \code{max\_\-element} from the
above example is implemented. One might expect that \emph{now} we will
again see all these awkward partial specializations, esoteric pattern
matching, etc. Well, let's see:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
template< typename Predicate >
struct select_max
{
    template< typename OldIterator, typename Iterator >
    struct apply
    {
        typedef typename mpl::apply<
              Predicate
            , typename OldIterator::type
            , typename Iterator::type
            >::type condition_;

        typedef typename mpl::select_if<
              condition_
            , Iterator
            , OldIterator
            >::type type;
    };
};
} // namespace aux 

template<
      typename Sequence
    , typename Predicate
    >
struct max_element
{
    typedef typename mpl::iter_fold<    
          Sequence
        , typename mpl::begin<Sequence>::type
        , aux::select_max<Predicate>
        >::type type;
};
\end{verbatim}
\end{codesamp}
}

The first thing to notice here is that this algorithm
is implemented in terms of another one: \code{iter\_\-fold}.  In fact,
this is probably the most important point of the example, because
nearly all other generic sequence algorithms in the library are
implemented in terms of \code{iter\_\-fold}.  If a user ever should
need to implement her own sequence algorithm, she'll almost certainly
be able to do it using this primitive, which means she won't have to
resort to implementing hand-crafted iteration, pattern matching of
special cases for loop termination, or workarounds for lack of partial
specialization. It also means that her algorithm will automatically
benefit any optimizations the library has implemented, (e.g. recursion
unrolling), and that it will work with any sequence that is a model of
ForwardSequence, because \code{iter\_\-fold} does not require any more
of its sequence argument.

\code{iter\_\-fold} is basically a compile-time equivalent of the
\emph{fold} or \emph{reduce} functions that comprise the basic and
well-known primitives of many functional programming languages. An
analogy more familiar to a \Cpp\ programmer would be
\code{std::accumulate} algorithm from the \Cpp\ standard
library. However, \code{iter\_\-fold} is designed to take advantage of
the natural characteristics of recursive traversal: it accepts
\emph{two} \mfn\ class arguments, the first of which is applied to the
state ``on the way in'' and the second of which is applied ``on the
way out''.

The
interface to \code{iter\_\-fold} is defined in \code{mpl} as follows:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Sequence
    , typename InitialState
    , typename ForwardOp
    , typename BackwardOp = identity<_1>
    >
struct iter_fold
{
    typedef ... type;
};
\end{verbatim}
\end{codesamp}
}

% it's not really ``implementation-defined'', but unspecified.

The algorithm ``returns'' the result of two-way successive
applications of binary \code{ForwardOp} and \code{BackwardOp}
operations to iterators in range [\code{begin<Sequence>::type},
\code{end<Sequence>::type}) and previous result of an operation; the
\code{InitialState} is logically placed before the sequence and
included in the forward traversal. The result \code{type} is identical
to \code{InitialState} if the sequence is empty.  Of course the MPL
also provides higher-level \code{fold} and \code{fold\_\-reverse}
algorithms which wrap \code{iter\_\-fold} to accommodate its most
common usage patterns.

\subsubsection{Sequences of Numbers}

What we've seen so far were sequences (and algorithms on sequences) of
types. It's very much possible and easy to manipulate values using the
library as well. The only thing to remember is that in \Cpp\ class
template non-type template parameters give us one more example of
non-polymorphic behavior.  In other words, if you declared a
metafunction to take a non-type template parameter, e.g.  \emph{long},
it's not possible to pass anything besides compile-time integral
constants to it:

{\small
\begin{codesamp}\begin{verbatim}
template< long N1, long N2 >
struct equal_to
{
    static bool const value = (N1 == N2);
};

equal_to<5,5>::value; // ok
equal_to<int,int>::value; // error!
\end{verbatim}
\end{codesamp}
}

And of course this doesn't work the other way around either:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<1,2,3,4,5> numbers; // error!
\end{verbatim}
\end{codesamp}
}

While this may be an obvious limitation, it imposes yet 
another dilemma on the library design - on one hand, we don't 
want to restrict users to type manipulations only, and on another 
hand, full support for integral manipulations would require at 
least duplication of most of the library facilities (ideally, 
if going this route, all the templates should be re-implemented 
for every integral type - \code{char}, \code{int}, \code{short},
\code{long}, etc.) - the same situation as we would have if we 
had chosen to represent \mfns\ as ordinary class templates.
The solution for this issue is the same as well - we represent 
integral values by wrapping them in types, so, for example, to 
create a list of numbers you write:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<
      mpl::int_c<1>
    , mpl::int_c<2>
    , mpl::int_c<3>
    , mpl::int_c<4>
    , mpl::int_c<5>
    > numbers;
\end{verbatim}
\end{codesamp}
}

Wrapping integral constants into types to make them 
first-class citizens is important well inside metaprograms, 
where you often don't know (and don't care) if the 
\mfns\ you are using operate on types, integral 
values, other \mfns\, or something else, like 
fixed-point or rational numbers (\code{mpl::fixed\_c} 
and \code{mpl::rational\_\-c}).

But from user's perspective, the above example is much more
verbose than the shorter one, the one that was incorrect. So, 
for the convenience purposes, the library does provide users 
with a template that takes non-type template parameters, but 
allows a more compact notation:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list_c<long,1,2,3,4,5> numbers;
\end{verbatim}
\end{codesamp}
}

There is a similar \code{vector} counterpart as well:

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::vector_c<long,1,2,3,4,5> numbers;
\end{verbatim}
\end{codesamp}
}


\subsubsection{Why External Functions for all Algorithms}

\begin{enumerate}
 \item while the nested functions notation in some cases is 
 less verbose, 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list<char,short,int,long> types;
typedef mpl::select_if<
      types::empty
    , long
    , types::back
    >::type t;
\end{verbatim}
\end{codesamp}
}

it is also less generic/more intrusive; requiring a sequence 
class to implement \code{size}, \code{empty}, \code{at}, etc. 
algorithms as members is often unnecessary and over restrictive. 
In many cases the default implementations provided by the library 
are sufficient.
Currently the only requirement that a ``foreign'' sequence should 
conform to in order to be used with the library algorithms is to 
implement external \code{begin}/\code{end} \mfns; you 
don't have to modify your sequence code; with the requirement to 
provide these as nested functions that wouldn't be the case anymore. 

\item if a nested function has at least one argument, and it's 
invoked on a sequence that is a template parameter, or depends 
on a template parameter, the notation actually becomes more 
verbose, e.g. 

{\small
\begin{codesamp}\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        // invoking 'at' nested metafunction on a Sequence class
        typedef typename Sequence::template at<N>::type type;
    };
};
\end{verbatim}
\end{codesamp}
}

comparing to the current 

{\small
\begin{codesamp}\begin{verbatim}
struct my_func
{
    template< typename Sequence, typename N > struct apply
    {
        typedef typename mpl::at< N,Sequence >::type type;
    };
};
\end{verbatim}
\end{codesamp}
}

\item placing functions inside of a sequence class makes 
impossible to pass them around as predicates/function classes: 

{\small
\begin{codesamp}\begin{verbatim}
typedef mpl::list< seq1,seq2,seq3 > sequences; // list of sequences
// find first non-empty sequence
typedef mpl::find_if< sequences, mpl::size<_1> >::type itor;
\end{verbatim}
\end{codesamp}
}

instead, you have to write an explicit predicate for every such case, 

{\small
\begin{codesamp}\begin{verbatim}
struct size_pred
{
    template< typename Sequence > struct apply
    {
        typedef typename Sequence::size type;
    };
};

// find first non-empty sequence
typedef mpl::find_if< sequences,size_pred >::type itor;
\end{verbatim}
\end{codesamp}
}

\end{enumerate}

 
  \subsubsection{A Variety of Sequences}

Previous efforts to provide generalized \mping\ facilities for C++
have always concentrated on \code{cons}-style type lists and a few
core algorithms like 'size' and 'at' which are tied to the specific
sequence implementation. Such systems have an elegant simplicity
reminiscent of the analogous functionality in pure functional Lisp. It
is much more time-consuming to implement even a basic set of the
sequence algorithms provided by equivalent run-time libraries (STL in
particular), but if we have learned anything from the STL it is that
tying those algorithms' implementations to a specific sequence
implementation is a misguided effort!

The truth is that there is no single ``best'' type sequence
implementation for the same reasons that there will never be a single
``best'' runtime sequence implementation. Furthermore, there are
\emph{already} quite a number of type list implementations in use
today, and just as the STL algorithms can operate on sequences which
don't come from STL containers, so the MPL algorithms are designed to
work with foreign type sequences.

It may be an eye-opening fact for some that type lists are not the
only useful compile-time sequence. Again, the need for a variety of
compile-time containers arises for the same reasons that we have
lists, vectors, deques, and sets in the \Cpp\ standard library -
different containers have different functional and performance
characteristics which determine not only applicability and efficiency
of particular algorithms, but also the expressiveness or verbosity of
the code that uses them. While runtime performance is not an issue for
\Cpp\ metaprograms, compilation speed is often a significant
bottleneck to advanced \Cpp\ software development \cite{Abr01}.

The \Mpl\ provides four built-in sequences: \code{list},
\code{list\_c} (really just a \code{list} of value
wrappers), \code{vector}, a randomly--accessible sequence of
fixed maximum size, and \code{range\_c}, a randomly--accessible
sequence of consecutive integral values. More important, however, is
its ability to adapt to arbitrary sequence types. The only core
operations that a sequence is required to provide in order to be used
with the library algorithms are \code{begin<>} and \code{end<>} \mfns\
which ``return'' iterators into to the sequence. As in the STL it is
the iterators which are used to implement most of the general purpose
sequence algorithms the library provides. Also as in STL, algorithm
specialization is used to take advantage of implementation knowledge
about particular sequences: many of the ``basic'' sequence operations
such as \code{back<>}, \code{front<>} \code{size<>} and \code{at<>}
are specialized on sequence type to provide a more efficient
implementation than the fully generic version.


  \subsubsection{Loop unrolling}

Almost coincidentally, loop unrolling can be as important to
compile-time iterative algorithms as it is to runtime algorithms. To
see why, one must first remember that all ``loops'' in \Cpp\
metaprograms are in fact implemented with recursion, and that the
depth of template instantiations can be a valuable resource in a
compiler implementation. In fact, Annex B of the \Cpp\ standard
\emph{recommends} a minimum depth of 17 recursively nested template
instantiations, but this is far too low for many serious \mpgms\ some
of which easily exceed the hard-coded instantiation limits of some
otherwise excellent compilers. To see how this works in action, let's
examine a straightforward implementation of the \code{fold} \mfn,
which combines some algorithm state with each element of a sequence:

{\small
\begin{codesamp}\begin{verbatim}
// Unspecialized version combines the initial state and first element
// and recurses to process the rest
template<class Start, class Finish, class State, class BinaryFunction>
struct fold
  : fold<typename Start::next, Finish
      , apply<BinaryFunction,State,typename Start::type>::type
      , BinaryFunction>
{
};

// Specialization for loop termination
template<class Finish, class State, class BinaryFunction>
struct fold<Finish,Finish,State,BinaryFunction>
{
    typedef State type;
};
\end{verbatim}
\end{codesamp}
}

Although simple and elegant, this implementation will always incur at
least as many levels of recursive template instantiation as there are
elements in the input sequence.\footnote{It could be much more,
depending on the complexity of the \code{apply<...>} expression, whose
depth is added to the overall recursion depth.} The library addresses
this problem by explicitly ``unrolling'' the recursion. To apply the
technique to our \code{fold} example, we begin by factoring out a
single step of the algorithm. Our \code{fold\_\-step} \mfn\ has two
results: \code{type} (the next state), and \code{iterator} (the next sequence position).

{\small
\begin{codesamp}\begin{verbatim}
template <class BinaryFunction, class State, class Start, class Finish>
struct fold_step
{
    typedef typename
         apply<BinaryFunction,State,typename Start::type>::type
    type;
    typedef typename Start::next iterator;
};
\end{verbatim}
\end{codesamp}
}

As with our main algorithm implementation, we specialize for the loop
termination condition so that the step becomes a no-op:

{\small
\begin{codesamp}\begin{verbatim}
template <class BinaryFunction, class State, class Finish>
struct fold_step<BinaryFunction,State,Finish,Finish>
{
    typedef State type;
    typedef Finish iterator;
};
\end{verbatim}
\end{codesamp}
}

Now we can now reduce \code{fold}'s instantiation depth by any
constant factor N simply by inserting N invocations of
\code{fold\_\-step}. Here we've chosen a factor of 4:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Start
    , typename Finish
    , typename State
    , typename BinaryFunction
    >
struct fold
{
 private:
    typedef fold_step<
        BinaryFunction,State,Start,Finish> next1;
    
    typedef fold_step<
        BinaryFunction,typename next1::type
      , typename next1::iterator,Finish> next2;
    
    typedef fold_step<
        BinaryFunction,typename next2::type
      , typename next2::iterator,Finish> next3;
    
    typedef fold_step<
        BinaryFunction,typename next3::type
      , typename next3::iterator,Finish> next4;
    
    typedef fold<
        typename next4::iterator
        , Finish
        , typename next4::type
        , BinaryFunction
     > recursion;
 public:
    typedef typename recursion::type type;
};
\end{verbatim}
\end{codesamp}
}

The \Mpl\ applies this unrolling technique across all algorithms with
an unrolling factor tuned according to the demands of the \Cpp\
implementation in use, and with an option for the user to override the
value.\footnote{This implementation detail is made relatively painless
through heavy reliance on the Boost Preprocessor Library, so only one
copy of the code needs to be maintained.} This fact enables users to
push beyond the \mping\ limits they would usually encounter with more
naive algorithm implementations. Experiments also show a small
increase in \mpgm\ instantiation speed on some compilers when loop
unrolling is used.

{\small
\begin{codesamp}\begin{verbatim}
\end{verbatim}
\end{codesamp}
}

\subsection{Code generation facilities}

There are cases, especially in domain of numeric computations, then 
you want make some part of calculations at compile-time, and then 
pass the results to a run-time part of the program for further 
processing. For example, suppose you've implemented a complex 
compile-time algorithm that works with fixed-point arithmetics:

{\small
\begin{codesamp}\begin{verbatim}
// fixed-point algorithm input
typedef mpl::vector<
      mpl::fixed_c<-1,2345678>
    , mpl::fixed_c<9,0001>
    // ..
    , mpl::fixed_c<3,14159>
    > input_data;

/*
  complex compile-time algorithm 
*/
typedef /*...*/ result_data;
\end{verbatim}
\end{codesamp}
}

Suppose the \code{result\_\-data} here is a sequence of 
\code{mpl::fixed\_\-c} types that keeps the results of your 
algorithm, and now you want to feed that result to run-time part 
of the algorithm. With \code{boost::mpl} you can do it this way:

{\small
\begin{codesamp}\begin{verbatim}
namespace aux {
struct push_back
{
    template< typename T > struct apply
    {
        template< typename C > void execute(C& c)
        {
            // in our case T() == fixed_c() == fixed_c().operator()()
            c.push_back(T());
        }
    };
};
}

double my_algorithm()
{
    // passing the results to the run-time part of the program
    std::vector<double> results;
    results.reserve(mpl::size<result_data>::value);
    mpl::for_each<result_data, aux::push_back>::execute(results);
    // ...
}
\end{verbatim}
\end{codesamp}
}

\code{for\_\-each<...>::\-execute} call there is what actually 
transfers the compile-time \code{result\_\-data} into run-time 
\code{std::vector<double> results}. The \code{for\_\-each} algorithm 
is one of the explicit facilities the library provides for run-time 
code generation:

{\small
\begin{codesamp}\begin{verbatim}
template<
      typename Sequence
    , typename Operation
    >
struct for_each
{
    template< typename T >
    static void execute(T& x)
    {
       // ...
    }

    static void execute()
    {
       // ...
    }
};
\end{verbatim}
\end{codesamp}
}

The semantics of \code{for\_\-each::\-execute} is simple: it 
iterates over a \code{Sequence} and applies the \code{Operation}
for each element \code{E} of the sequence:

{\small
\begin{codesamp}\begin{verbatim}
mpl::apply<Operation,E>::execute(x);
\end{verbatim}
\end{codesamp}
}

Applying this to our example, the 

{\small
\begin{codesamp}\begin{verbatim}
mpl::for_each<result_data, aux::push_back>::execute(results);
\end{verbatim}
\end{codesamp}
}

line is equivalent to this:

{\small
\begin{codesamp}\begin{verbatim}
mpl::apply< Operation, mpl::at_c<result_data,0>::type >::execute(results);
mpl::apply< Operation, mpl::at_c<result_data,1>::type >::execute(results);
// ...
mpl::apply< Operation, mpl::at_c<result_data,n>::type >::execute(results);
\end{verbatim}
\end{codesamp}
}

There are other ways to generate an analogous code, 
but they are much less expressive.


\section{Lambda facility}

Lambda is supposed to allow inline
composition of class templates into ``lambda expressions" that are
classes and therefore can be passed around as ordinary function
classes, and transformed into \mfn\ classes before application
using

{\small
\begin{codesamp}\begin{verbatim}
typedef lambda<expr>::type func;
\end{verbatim}
\end{codesamp}
}

expression. For example, \code{boost::remove\_\-const} traits is a 
class template
(obviously), and a \mfn{} in MPL terminology. The simplest example
of ``inline composition" of it would be something like

{\small
\begin{codesamp}\begin{verbatim}
typedef boost::remove_const<_1> expr;
\end{verbatim}
\end{codesamp}
}


and that forms a so called ``lambda expression", that is neither a function
class, not a \mfn{}, but can be passed around everywhere because
it's an ordinary C++ class, and all MPL facilities are polymorphic regarding
their arguments. Now, that lambda expression can be \emph{transformed} into a
\mfn\ class using MPL `lambda' facility:

{\small
\begin{codesamp}\begin{verbatim}
typedef boost::remove_const<_1> expr;
typedef lambda<expr>::type func;
\end{verbatim}
\end{codesamp}
}

Now \code{func} is an unary \mfn\ class and can be used as such - in
particular, it can be pass around, and it can be invoked (applied):

{\small
\begin{codesamp}\begin{verbatim}
typedef apply1<func,int const>::type res;
BOOST_MPL_ASSERT_IS_SAME(res, int);
\end{verbatim}
\end{codesamp}
}

or even

{\small
\begin{codesamp}\begin{verbatim}
typedef func::apply<int const>::type res;
BOOST_MPL_ASSERT_IS_SAME(res, int);
\end{verbatim}
\end{codesamp}
}

Inline composition is very syntactically appealing when you deal with
\mfn{}s, because it makes the expression obvious:

{\small
\begin{codesamp}\begin{verbatim}
typedef logical_or< less< size_of<_1>, 16>, boost::is_same<_1,_2> > expr;
typedef lambda<expr>::type func;
\end{verbatim}
\end{codesamp}
}

And you don't have to do the last part (\code{typedef lambda<expr>::type func})
yourself, because all the algorithms do this to any of their \mfn\ class
operands internally (\code{lambda<T>::type} expression applied to a \mfn\ class
gives back the same \mfn\ class, so it's safe to apply the expression
unconditionally).

The alternative way to get an equivalent to the above \mfn\ class would
be:

{\small
\begin{codesamp}\begin{verbatim}
typedef bind< make_f2<logical_or>
    , bind< make_f2<less>
        , bind< make_f1<size_of>, _1 >
        , 16
        >
    , bind< make_f2<boost::is_same>, _1,_2>
    > func;
\end{verbatim}
\end{codesamp}
}

Or to use \code{compose\_\-{*}} an similar way. Here, we use 
\code{make\_\-f{*}}' templates to
convert \mfn{} into \mfn\ classes (and yes, they do require the
template template parameters), and then we combine them using \code{bind}.
The transformation from this form to the above inline lambda expression and
visa-versa is mechanic, and that's what essentially \code{typedef
lambda<expr>::type} expression does.

Now, in absence of lambda, MPL enables one to write the above in a little
bit less cumbersome way by fully \emph{specializing} its own \mfns\
(algorithms, primitives, etc.) for the case when all the arguments are
replaced by lambda placeholders in alphabetical order. For example, the original
\code{mpl::less} template looks like this:

{\small
\begin{codesamp}\begin{verbatim}
template< typename T0, typename T1 >
struct less 
{
    typedef bool_c<(T1::value op T2::value)> type;
};
\end{verbatim}
\end{codesamp}
}

and it's specialized like this:

{\small
\begin{codesamp}\begin{verbatim}
template<>
struct less<_1,_2>
{
    template< typename T0, typename T1 > struct apply
    {
        typedef bool_c<(T1::value op T2::value)> type;
    };
};
\end{verbatim}
\end{codesamp}
}

The same is done for everything else in the library that is represented by
top level class template (\mfn{}), so, with this knowledge, the
previous awkward bind example can be rewritten as:

{\small
\begin{codesamp}\begin{verbatim}
typedef bind< logical_or<_1,_2>
    , bind< less<_1,_2>, size_of<_1>, 16 >
    , bind< make_f2<boost::is_same>, _1,_2 >
    > func;
\end{verbatim}
\end{codesamp}
}

Note that you still have to wrap \code{is\_\-same} into \code{make\_\-f2},
 because it's a foreign template.

Now, about combining class template metufunctions and \mfn\ 
classes in the single lambda expression - it can be done like this:

{\small
\begin{codesamp}\begin{verbatim}
struct my_predicate
{
    template< typename T1, typename T2 > struct apply
    {
        //...
    };
};

typedef logical_or<
      less< size_of<_1>, 16>
    , my_predicate // here
    > expr;
\end{verbatim}
\end{codesamp}
}

or, if, for example, you want to bind something to one of it's arguments (or
change the order of parameters), then either

{\small
\begin{codesamp}\begin{verbatim}
typedef logical_or<
      less< size_of<_1>, 16>
    , bind<my_predicate,int,_1>::type // here
    > expr;
\end{verbatim}
\end{codesamp}
}

or

{\small
\begin{codesamp}\begin{verbatim}
typedef logical_or<
      less< size_of<_1>, 16>
    , my_predicate::apply<int,_1> // here
    > expr;
\end{verbatim}
\end{codesamp}
}


\section{An advanced example - compile-time FSM generator}


Finite state machines (FSM) are an important tool of 
describing and implementing controlling program behavior 
\cite{HU79}, \cite{Mar98}. They also are a good example of the domain 
where some \mping{} can be applied to reduce the amount of 
repetitive and boilerplate operations one have to perform 
in order to implement these simple mathematical models in 
code. Below we present a simple state machine generator that 
has been implemented using \Mpl facilities. The generator 
takes a compile-time automata description, and turns it 
into \Cpp code that implements the FSM at run-time. The 
FSM description is basically a combination of states and 
events + a state transition table (STT) that ties them 
all together. The generator walks through the table and 
generates the state machine's \code{process\_\-event} 
method that is essentially what a FSM is about. 

Suppose we want to implement a simple music player using 
a finite state machine model. The state transition table 
for the FSM is shown in Table 1. The STT format reflects 
the way one usually describes the behavior of a FSM in 
plain English. For example, the first line of the table 
can be read as follows: ``If the model is in the \code{stopped}
state, and the \code{play\_\-event} is received, then the 
\code{do\_\-play} transition function is called, and the model 
goes into the \code{playing} state''.

\begin{figure}[t]
\vskip.2in
\caption{Player's state transition diagram.}
\end{figure}

\begin{table}[ht]
\begin{center}
\caption[Player's state transition table with actions.]%<-- this version will appear in List of Tables
{Player's state transition table with actions.}%<-- this version will appear on page
\begin{tabular*}{\textwidth}{@{\extracolsep{\fill}}cccc}
\sphline
\it State &\it Event &\it Next State &\it Transition Function\cr
\sphline
stopped&play\_event&playing&do\_play\cr
playing&stop\_event&stopped&do\_stop\cr
playing&pause\_event&paused&do\_pause\cr
paused&play\_event&playing&do\_resume\cr
paused&stop\_event&stopped&do\_stop\cr
\sphline
\end{tabular*}
\end{center}
\end{table}

%%% can we kill the ``_event'' suffix here?

The transition table provides us with complete formal 
definition of the target FSM, and there are several ways to 
transform that definition into code. For example, if we define
states as members of enumeration type, and events as classes 
derived from some base \code{event}
class (they need to be passed to action functions, and they may
contain some event-specific information for an action), 

{\small
\begin{codesamp}\begin{verbatim}
class player
{
 public:
    // event declarations
    struct event;
    struct play_event;
    struct stop_event;
    struct pause_event;

    // ``input" function
    void process_event(event const&); // throws

 private:
    // states
    enum state_t { stopped, playing, paused };

    // transition functions
    void do_play(play_event const&);
    void do_stop(stop_event const&);
    void do_pause(pause_event const&);
    void do_resume(play_event const&);

 private:
    state_t m_state;
};
\end{verbatim}
\end{codesamp}
}

%%% IMO this implementation bends over backward to be inefficient. My
%%% first thought would have been:
%%
%%     // ``input" function
%%     template <class Event>
%%     void process_event(Event const&); // throws
%%
%%  private:
%%     // states
%%     enum state_t { stopped, playing, paused };
%%
%%     // transition functions
%%     void transition(play_event const&);
%%     void transition(stop_event const&);
%%     void transition(pause_event const&);
%%     void transition(play_event const&);
%%
%%% Which avoids RTTI AFAICT.
%%%
%%% And then, once I realized that it wouldn't work ;-) I would have
%%% used an event base class which contained its own event ID. There
%%% are lots of ways to achieve this:
%%
%% struct event_base
%% {
%%   event_base(unsigned id) : m_id(id) {}
%% protected:
%%   static unsigned counter;
%% private:
%%   unsigned m_id;
%% };
%% template <class Event> struct event : event_base
%% {
%%    event() : event_base(id) {}
%%    virtual ~event();
%%    static unsigned id;
%% };
%% template <class Event> struct event_base<Event>::id = counter++;
%% struct play : event<play> { ... };

then the most straightforward way to derive the FSM 
implementation from the above table would be something 
like this:

{\small
\begin{codesamp}\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)
    {
        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else if (m_state == playing)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(pause_event))
        {
            do_pause(static_cast<pause_event const&>(e));
            m_state = paused;
            return;
        }
    }
    else if (m_state == paused)
    {
        if (typeid(e) == typeid(stop_event))
        {
            do_stop(static_cast<stop_event const&>(e));
            m_state = stopped;
            return;
        }

        if (typeid(e) == typeid(play_event))
        {
            do_play(static_cast<play_event const&>(e));
            m_state = playing;
            return;
        }
    }
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );
}
\end{verbatim}
\end{codesamp}
}

%%% Not sure the part below is too relevant
%%% Note that despite seemed obviousness of optimization of making 
%%% a transition function to return the next state in not such a 
%%% good idea. While it will reduce the amount of lines required 
%%% to describe a single transition, it also would take the 
%%% transition control away from FSM driver function into 
%%% application-level code. For one, that would mean and you'd no 
%%% longer be able to say in what state the machine is going to 
%%% move after it handles a specific event - you'll have to look 
%%% into transition function itself. [...] 

Although there is nothing particularly wrong with implementing 
a FSM's structure using nested \code{if} (or \code{switch-case})
statements, the obvious thing about this approach is that it 
doesn't scale - even for our simple FSM the 
\code{process\_\-event} function is already more than 50 lines
long. One way to reduce the maintenance problems would be to 
factor bodies of top-level \code{if} statements in separate 
event processing functions, one for each state:

%%% I think a simple example of a switch statement from a naive lexer
%%% implementation would suffice to show why the switch/if approach is
%%% bad, and we could afford to show just a single example of this,
%%% taking it on faith that people will understand.

{\small
\begin{codesamp}\begin{verbatim}
void
player::process_event(event const& e)
{
    if (m_state == stopped)  m_state = process_stopped_state_event(e);
    else if (m_state == playing) m_state = process_playing_state_event(e);
    else if (m_state == paused) m_state = process_paused_state_event(e);
    else
    {
        throw logic_error(
            boost::format("unknown state: %d")
                % static_cast<int>(m_state)
            );
    }
}
\end{verbatim}
\end{codesamp}
}

where, for example, \code{process\_\-playing\_\-state\_\-event} 
function would look like this:

{\small
\begin{codesamp}\begin{verbatim}
player::state_t
player::process_stopped_state_event(event const& e)
{
    if (typeid(e) == typeid(stop_event))
    {
        do_stop(static_cast<stop_event const&>(e));
        return stopped;
    }

    if (typeid(e) == typeid(pause_event))
    {
        do_pause(static_cast<pause_event const&>(e));
        return paused;
    }

    throw std::logic_error(
        "unexpected event: " + typeid(e).name()
        );

    return m_state;
}
\end{verbatim}
\end{codesamp}
}

Still, if the number of events being handled from particular 
state is large, the problem remains. Of course, the fact that 
the technique tends to lead to large functions is only one 
side of the problem; after all, you can split the functions 
even further - and that's in fact what the State pattern does.

%%% This is a good point
Another obvious thing about it that most of the code is 
boilerplate. What you tend to do with boilerplate code is copy 
and paste it, and then change names etc. to adjust it to its new 
location, and that's there the errors are most likely to creep in
- since all the lines of events processing look alike 
(structurally), it's very easy to overlook or forget something 
that's need to be changed, and many of such errors won't appear 
until the runtime.

Note that all the implementations we've looked on has this common 
trait - the transition table of our FSM is just a 5-lines table, 
and ideally, we would like the skeleton implementation of the 
automata's controlling logic to be equally small (or, at least, 
to look equally small, e.g. to be encapsulated in some form so 
we never see/worry about it). 

\subsection{Implementing it}

To represent the TTS in \Cpp\ program, we define 
a \code{transition} class template that represents a single line 
of the table, and than the table itself can be represented as a 
sequence of such lines:

{\small
\begin{codesamp}\begin{verbatim}
typedef list<
      transition<stopped, play_event,  playing, &player::do_play>
    , transition<playing, stop_event,  stopped, &player::do_stop>
    , transition<playing, pause_event, paused,  &player::do_pause>
    , transition<paused,  play_event,  playing, &player::do_resume>
    , transition<paused,  stop_event,  stopped, &player::do_stop>
    >::type transition_table;
\end{verbatim}
\end{codesamp}
}

Now, the complete FSM will look like this:

{\small
\begin{codesamp}\begin{verbatim}
class player
    : state_machine<player>
{
 private:
    typedef player self_t;

    // state invariants
    void stopped_state_invariant();
    void playing_state_invariant();
    void paused_state_invariant();

    // states (invariants are passed as non-type template arguments,
    // and are called then the FSM enters the corresponding state)
    typedef state<0, &self_t::stopped_state_invariant> stopped;
    typedef state<1, &self_t::playing_state_invariant> playing;
    typedef state<2, &self_t::paused_state_invariant> paused;

 private:
    // event declarations; events are represented as types, 
    // and can carry a specific data for each event;
    // but it's not needed for generator, so we define them later
    struct play_event;
    struct stop_event;
    struct pause_event;

    // transition functions
    void do_play(play_event const&);
    void do_stop(stop_event const&);
    void do_pause(pause_event const&);
    void do_resume(play_event const&);

    // STT
    friend class state_machine<player>;
    typedef mpl::list<
          transition<stopped, play_event,  playing, &player::do_play>
        , transition<playing, stop_event,  stopped, &player::do_stop>
        , transition<playing, pause_event, paused,  &player::do_pause>
        , transition<paused,  play_event,  playing, &player::do_resume>
        , transition<paused,  stop_event,  stopped, &player::do_stop>
        >::type transition_table;
};
\end{verbatim}
\end{codesamp}
}

That's all - the above will generate a complete FSM 
implementation according to our specification. The only thing we 
need to start using it is to define the events types (that were 
just forward declared before):

{\small
\begin{codesamp}\begin{verbatim}
// event definitions
struct player::play_event
    : player::event
{
};

// ...
\end{verbatim}
\end{codesamp}
}

The usage is simple as well:

{\small
\begin{codesamp}\begin{verbatim}
int main()
{
    // usage example
    player p;
    p.process_event(player::play_event());
    p.process_event(player::pause_event());
    p.process_event(player::play_event());
    p.process_event(player::stop_event());
    return 0;
}
\end{verbatim}
\end{codesamp}
}

\subsection{Related work}

A notable prior work in the field of automation of general-purpose 
state machine implementation in \Cpp\ is the Robert Martin's State 
Machine Compiler \cite{SMC}. The SMC takes an ASCII description of the 
machine's state transition table and produces a \Cpp\ code that 
implements the FSM using a variation of State design pattern \cite{Hun91},
\cite{GHJ+95}. \cite{Laf00} presents another approach, where no external tools 
are used, and the FSMs are table driven. 


\begin{glossary}
  \term{Metaprogramming} the creation of programs which generate other
  programs.

  \term{Metadata} the program specification processed by a \mpgm.

  \term{Meta-language} defines the \mdat constructs accepted by the \mpgm.

  \term{Higher-Order Function} is a function that can take other
  functions as arguments, and/or return functions as
  results. Higher-order functions are a distinguishing features of the
  modern functional languages \cite{Hud89}.

  \term{polymorphic} A function is \emph{polymorphic} if it can take
  arguments of an arbitrary type (a \Cpp\ term from the run-time world
  would be ``generic'')
\end{glossary}

\section{Acknowledgements}

Aleksey Gurtovoy originated most of the ideas behind and wrote nearly
all of the MPL's implementation.

Peter Dimov contributed the \code{bind} functionality without which
compile-time lambda expressions wouldn't have been possible.

The \Mpl\ implementation would have been much more difficult without
Vesa Karvonen's wonderful Boost Preprocessor Metaprogramming Library.

{%\normallatexbib
\bibliographystyle{apalike}
%%\chapbblname{mpl}
\chapbibliography{refs}
}

%%\begin{chapthebibliography}{1}
%%\end{chapthebibliography}

\end{document}
% LocalWords:  Aleksey David Gurtovoy Abrahams MPL STL Boost boost
