<?xml version="1.0" standalone="yes"?>
<!DOCTYPE library PUBLIC "-//Boost//DTD BoostBook XML V1.0//EN"
     "http://www.boost.org/tools/boostbook/dtd/boostbook.dtd"
[
    <!ENTITY % entities SYSTEM "program_options.ent" >
    %entities;
]>
<section id="program_options.howto">

  <title>How To</title>

  <para>This section describes how the library can be used in specific situations.</para>

  <section>
    <title>Unicode support</title>

    <para>To use the library with Unicode, you'd need to:
      <itemizedlist>
        <listitem>
          <para>Use Unicode-aware parsers for Unicode input</para>
        </listitem>
        <listitem>
          <para>Require Unicode support for options which need it</para>
        </listitem>
      </itemizedlist>
    </para>

    <para>Most of the parsers have Unicode versions. For example, the
      &parse_command_line; function has an overload which takes
      <code>wchar_t</code> strings, instead of ordinary <code>char</code>.
    </para>

    <para>Even if some of the parsers are Unicode-aware, it does not mean you
    need to change definition of all the options. In fact, for many options,
    like integer ones, it makes no sense. To make use of Unicode you'll need
    <emphasis>some</emphasis> Unicode-aware options. They are different from
    ordinary options in that they accept <code>wstring</code> input, and
    process it using wide character streams. Creating an Unicode-aware option
    is easy: just use the the <code>wvalue</code> function instead of the
    regular <code>value</code>.
    </para>

    <para>When an ascii parser passes data to an ascii option, or a Unicode
      parser passes data to a Unicode option, the data are not changed at
      all. So, the ascii option will see a string in local 8-bit encoding, and
      the Unicode option will see whatever string was passed as the Unicode
      input.
    </para>

    <para>What happens when Unicode data is passed to an ascii option, and
      vice versa? The library automatically performs the conversion from
      Unicode to local 8-bit encoding. For example, if command line is in
      ascii, but you use <code>wstring</code> options, then the ascii input
      will be converted into Unicode.
    </para>

    <para>To perform the conversion, the library uses the <code>codecvt&lt;wchar_t,
    char&gt;</code> locale facet from the global locale. If
    you want to work with strings that use local 8-bit encoding (as opposed to
    7-bit ascii subset), your application should start with:
      <programlisting>
locale::global(locale(""));
      </programlisting>
      which would set up the conversion facet according to the user's selected
      locale. 
    </para>

    <para>It's wise to check the status of the C++ locale support on your
      implementation, though. The quick test involves three steps:
      <orderedlist>
        <listitem>
          <para>Go the the "test" directory and built the "test_convert" binary.</para>
        </listitem>
        <listitem>
          <para>Set some non-ascii locale in the environemt. On Linux, one can
          run, for example: <screen>
$ export LC_CTYPE=ru_RU.KOI8-R
</screen>
          </para>
        </listitem>
        <listitem>
          <para>Run the "test_convert" binary passing it as parameter
          arbitrary non-ascii string in selected encoding. If you see a list
          of Unicode codepoints, everything's OK. Otherwise, locale support on
          your system might be broken.</para>
        </listitem>
      </orderedlist>
    </para>

    </section>

</section>

<!--
     Local Variables:
     mode: xml
     sgml-indent-data: t     
     sgml-parent-document: ("program_options.xml" "section")
     sgml-set-face: t
     End:
-->
